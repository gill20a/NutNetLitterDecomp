#Enter code here
#File path
setwd("~/Dropbox/UMN/NutNet Litter Decay/")
# data<-read.csv("20190312_NutNet_Masterlist.csv", header=T, sep=",")
data<-read.csv("5.23.2019 Nutnet Masterlist.csv", header=T, sep=",")
# data<-read.csv("dummy data.csv", header=T, sep=",")
dim(data)
# data<-read.csv("", header=T, sep=",")
head(data)
colnames(data)

library(stats4)
library(bbmle)
library(qpcR)

unique(data$Site_Text)
class(data$Site_Text)
data$Site_Text<-as.character(data$Site_Text)
unique(data$Trt)
CBGB<-data[data$Site_Text=="CBGB-Iowa",] #1-10
Sierra<-data[data$Site_Text=="Sierra Foothill REC ",] #11-20
Bunch<-data[data$Site_Text=="Bunchgrass - Andrews LTER ",] #21-30
Boulder<-data[data$Site_Text=="Boulder ",] #31-40
UNC<-data[data$Site_Text=="UNC ",] #41-50
CDR<-data[data$Site_Text=="Cedar Creek LTER ",] #51-60
Elliott<-data[data$Site_Text=="Elliott Chaparral Reserve ",] #61-70
Halls<-data[data$Site_Text=="Halls Prairie ",] #71-80
Lookout<-data[data$Site_Text=="Lookout - Andrews LTER ",] #81-90
Hopland<-data[data$Site_Text=="Hopland REC ",] #91-100
McL<-data[data$Site_Text=="Mclaughlin UCNRS ",] #101-110
Sagehen<-data[data$Site_Text=="Sagehen UCNRS ",] #111-120
Sedgwick<-data[data$Site_Text=="Sedgwick Reserve UCNRS ",] #121-130
Sheep<-data[data$Site_Text=="Sheep Experiment Station ",] #131-140
Spindle<-data[data$Site_Text=="Spindletop Agricultural Farm ",]#141-150
Val<-data[data$Site_Text=="Val Mustair ",]#151-160
Bogong<-data[data$Site_Text=="Bogong High Plains ",]#161-170
Burrawan<-data[data$Site_Text=="Burrawan ",]#171-180
Cowichan<-data[data$Site_Text=="Cowichan ",]#181-190
Fru<-data[data$Site_Text=="Früebüel ",]#191-200
Kiny<-data[data$Site_Text=="Kinypanial ",]#201-210
Caroline<-data[data$Site_Text=="Mt. Caroline ",]#211-220

dim(Sedgwick)
#vectors for k values (col 1 or 1&2) and sse (col 2)
single.k=array(0,dim=c(220,1))
double.k=array(0,dim=c(220,3))
asymptotic.k=array(0,dim=c(220,3))
weibull=array(0,dim=c(220,5))

#arrays for obs,pred,res
single.pred=array(0,dim=c(220,4))		#col: 1=Mt,2=t,3=pred,4=res
double.pred=array(0,dim=c(220,4))		#col: 1=Mt,2=t,3=pred,4=res
asymptotic.pred=array(0,dim=c(220,6))	#col: 1=Mt,2=t,3=pred,4=res
weibull.pred=array(0,dim=c(220,6))	#col: 1=Mt,2=t,3=pred,4=res

#arrays to store AICc values
a.aicc=array(0,dim=c(220,10)) #3aicc; 3weights; single, asym, double

#Here, models are fit one at a time. You could make this a loop if you 
#are convinced all your models will converge using the same starting values.
#I never have such luck.

#choose rep or set of CBGB points to fit(here identified by the CBGB column ID)

half.life.calc=function(nls.mod){
  pars= coef(nls.mod)
  hl=pars[1] * (log(2))^(1/pars[2])
  names(hl)="half.life"
  return(hl)
}

mrt.calc=function(nls.mod){
  pars= coef(nls.mod)
  mrt=pars[1] * gamma(1+(1/pars[2]))
  names(mrt)="mrt"
  return(mrt)
}

LLS = function(y,k){
  Mhat=1*exp(-k*xNA$t) #creates a vector of=length to obs of preds
  ssq = sum((Mhat - xNA$Mt)^2)
  sigma = sqrt(ssq/length(xNA$Mt))
  return(-sum(dnorm(xNA$Mt,mean=Mhat,sd=sigma,log = TRUE)))
}

LLA = function(y,k,A){
  Mhat=A+((1-A)*exp(-k*xNA$t)) #creates a vector of=length to obs of preds
  ssq = sum((Mhat - xNA$Mt)^2)
  sigma = sqrt(ssq/length(xNA$Mt))
  return(-sum(dnorm(xNA$Mt,mean=Mhat,sd=sigma,log = TRUE)))
}

LLD = function(y,ks,k,A){
  Mhat=A*exp(-ks*xNA$t)+(1-A)*exp(-k*xNA$t) #creates a vector of=length to obs of preds
  ssq = sum((Mhat - xNA$Mt)^2)
  #browser()
  sigma = sqrt(ssq/length(xNA$Mt))
  return(-sum(dnorm(xNA$Mt,mean=Mhat,sd=sigma,log = TRUE)))
}


##CBGB######################################################################################################
# 
i<-1
s1=subset(CBGB,CBGB$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-2
s1=subset(CBGB,CBGB$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-3
s1=subset(CBGB,CBGB$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-4
s1=subset(CBGB,CBGB$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-5
s1=subset(CBGB,CBGB$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-6
s1=subset(CBGB,CBGB$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-7
s1=subset(CBGB,CBGB$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-8
s1=subset(CBGB,CBGB$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-9
s1=subset(CBGB,CBGB$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CBGB$Trt)
i<-10
s1=subset(CBGB,CBGB$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.0001), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.5,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]
CBGB_a.aicc<-a.aicc



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CBGB - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Sierra######################################################################################################
# 
i<-11
s1=subset(Sierra,Sierra$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.01,ks=0.001,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=100, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-12
s1=subset(Sierra,Sierra$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-13
s1=subset(Sierra,Sierra$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-14
s1=subset(Sierra,Sierra$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-15
s1=subset(Sierra,Sierra$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-16
s1=subset(Sierra,Sierra$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-17
s1=subset(Sierra,Sierra$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-18
s1=subset(Sierra,Sierra$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.005,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-19
s1=subset(Sierra,Sierra$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.002), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sierra$Trt)
i<-20
s1=subset(Sierra,Sierra$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.01,0.01,0.01),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sierra - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Bunch######################################################################################################
# 
i<-21
s1=subset(Bunch,Bunch$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.01,ks=0.001,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=100, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-22
s1=subset(Bunch,Bunch$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-23
s1=subset(Bunch,Bunch$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-24
s1=subset(Bunch,Bunch$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-25
s1=subset(Bunch,Bunch$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-26
s1=subset(Bunch,Bunch$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-27
s1=subset(Bunch,Bunch$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-28
s1=subset(Bunch,Bunch$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-29
s1=subset(Bunch,Bunch$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bunch$Trt)
i<-30
s1=subset(Bunch,Bunch$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bunch - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")



##Boulder######################################################################################################
# 
i<-31
s1=subset(Boulder,Boulder$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.01,ks=0.001,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=100, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-32
s1=subset(Boulder,Boulder$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.05), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-33
s1=subset(Boulder,Boulder$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=1,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-34
s1=subset(Boulder,Boulder$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = .9,A=0.002), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))


#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-35
s1=subset(Boulder,Boulder$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001),control=list(maxit=10000, trace=TRUE))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-36
s1=subset(Boulder,Boulder$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001),control=list(maxit=1000000, trace=TRUE))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-37
s1=subset(Boulder,Boulder$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-38
s1=subset(Boulder,Boulder$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-39
s1=subset(Boulder,Boulder$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Boulder$Trt)
i<-40
s1=subset(Boulder,Boulder$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = .10,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Boulder - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##UNC######################################################################################################
# 
i<-41
s1=subset(UNC,UNC$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.000001,0.000001,0.000001),control=list(maxit=100000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-42
s1=subset(UNC,UNC$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-43
s1=subset(UNC,UNC$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]


single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=100000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]

a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-44
s1=subset(UNC,UNC$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = .9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001),control=list(maxit=100000))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-45
s1=subset(UNC,UNC$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-46
s1=subset(UNC,UNC$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-47
s1=subset(UNC,UNC$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = .05,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-48
s1=subset(UNC,UNC$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.05), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-49
s1=subset(UNC,UNC$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(UNC$Trt)
i<-50
s1=subset(UNC,UNC$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="UNC - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")





##CDR######################################################################################################
# 
i<-51
s1=subset(CDR,CDR$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.01,ks=0.001,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=100, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-52
s1=subset(CDR,CDR$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.01,0.01))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-53
s1=subset(CDR,CDR$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-54
s1=subset(CDR,CDR$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-55
s1=subset(CDR,CDR$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-56
s1=subset(CDR,CDR$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-57
s1=subset(CDR,CDR$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-58
s1=subset(CDR,CDR$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-59
s1=subset(CDR,CDR$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(CDR$Trt)
i<-60
s1=subset(CDR,CDR$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="CDR - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Elliott######################################################################################################
# 
i<-61
s1=subset(Elliott,Elliott$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-62
s1=subset(Elliott,Elliott$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-63
s1=subset(Elliott,Elliott$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-64
s1=subset(Elliott,Elliott$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-65
s1=subset(Elliott,Elliott$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.05), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-66
s1=subset(Elliott,Elliott$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-67
s1=subset(Elliott,Elliott$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-68
s1=subset(Elliott,Elliott$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.05), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.1,0.1))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-69
s1=subset(Elliott,Elliott$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Elliott$Trt)
i<-70
s1=subset(Elliott,Elliott$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Elliott - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Halls######################################################################################################
# 
i<-71
s1=subset(Halls,Halls$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-72
s1=subset(Halls,Halls$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-73
s1=subset(Halls,Halls$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-74
s1=subset(Halls,Halls$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-75
s1=subset(Halls,Halls$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-76
s1=subset(Halls,Halls$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-77
s1=subset(Halls,Halls$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-78
s1=subset(Halls,Halls$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-79
s1=subset(Halls,Halls$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Halls$Trt)
i<-80
s1=subset(Halls,Halls$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Halls - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Lookout######################################################################################################
# 
i<-81
s1=subset(Lookout,Lookout$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-82
s1=subset(Lookout,Lookout$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-83
s1=subset(Lookout,Lookout$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-84
s1=subset(Lookout,Lookout$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-85
s1=subset(Lookout,Lookout$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-86
s1=subset(Lookout,Lookout$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-87
s1=subset(Lookout,Lookout$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-88
s1=subset(Lookout,Lookout$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-89
s1=subset(Lookout,Lookout$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Lookout$Trt)
i<-90
s1=subset(Lookout,Lookout$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Lookout - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Hopland######################################################################################################
# 
i<-91
s1=subset(Hopland,Hopland$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-92
s1=subset(Hopland,Hopland$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-93
s1=subset(Hopland,Hopland$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-94
s1=subset(Hopland,Hopland$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-95
s1=subset(Hopland,Hopland$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-96
s1=subset(Hopland,Hopland$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-97
s1=subset(Hopland,Hopland$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-98
s1=subset(Hopland,Hopland$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-99
s1=subset(Hopland,Hopland$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Hopland$Trt)
i<-100
s1=subset(Hopland,Hopland$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Hopland - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##McL######################################################################################################
# 
i<-101
s1=subset(McL,McL$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-102
s1=subset(McL,McL$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-103
s1=subset(McL,McL$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-104
s1=subset(McL,McL$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-105
s1=subset(McL,McL$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-106
s1=subset(McL,McL$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-107
s1=subset(McL,McL$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-108
s1=subset(McL,McL$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-109
s1=subset(McL,McL$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(McL$Trt)
i<-110
s1=subset(McL,McL$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="McL - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Sagehen######################################################################################################
# 
i<-111
s1=subset(Sagehen,Sagehen$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-112
s1=subset(Sagehen,Sagehen$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-113
s1=subset(Sagehen,Sagehen$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.1,0.1,0.1),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-114
s1=subset(Sagehen,Sagehen$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.5,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-115
s1=subset(Sagehen,Sagehen$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.9), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-116
s1=subset(Sagehen,Sagehen$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-117
s1=subset(Sagehen,Sagehen$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-118
s1=subset(Sagehen,Sagehen$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-119
s1=subset(Sagehen,Sagehen$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sagehen$Trt)
i<-120
s1=subset(Sagehen,Sagehen$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sagehen - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Sedgwick######################################################################################################
# 
i<-121
s1=subset(Sedgwick,Sedgwick$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-122
s1=subset(Sedgwick,Sedgwick$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-123
s1=subset(Sedgwick,Sedgwick$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-124
s1=subset(Sedgwick,Sedgwick$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-125
s1=subset(Sedgwick,Sedgwick$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-126
s1=subset(Sedgwick,Sedgwick$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-127
s1=subset(Sedgwick,Sedgwick$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-128
s1=subset(Sedgwick,Sedgwick$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-129
s1=subset(Sedgwick,Sedgwick$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sedgwick$Trt)
i<-130
s1=subset(Sedgwick,Sedgwick$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sedgwick - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Sheep######################################################################################################
# 
i<-131
s1=subset(Sheep,Sheep$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-132
s1=subset(Sheep,Sheep$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-133
s1=subset(Sheep,Sheep$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-134
s1=subset(Sheep,Sheep$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-135
s1=subset(Sheep,Sheep$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-136
s1=subset(Sheep,Sheep$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-137
s1=subset(Sheep,Sheep$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-138
s1=subset(Sheep,Sheep$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-139
s1=subset(Sheep,Sheep$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Sheep$Trt)
i<-140
s1=subset(Sheep,Sheep$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Sheep - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Spindle######################################################################################################
# 
i<-141
s1=subset(Spindle,Spindle$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-142
s1=subset(Spindle,Spindle$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-143
s1=subset(Spindle,Spindle$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-144
s1=subset(Spindle,Spindle$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-145
s1=subset(Spindle,Spindle$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-146
s1=subset(Spindle,Spindle$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-147
s1=subset(Spindle,Spindle$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-148
s1=subset(Spindle,Spindle$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-149
s1=subset(Spindle,Spindle$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Spindle$Trt)
i<-150
s1=subset(Spindle,Spindle$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Spindle - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Val######################################################################################################
# 
i<-151
s1=subset(Val,Val$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=0.01,A =0.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-152
s1=subset(Val,Val$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-153
s1=subset(Val,Val$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-154
s1=subset(Val,Val$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-155
s1=subset(Val,Val$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-156
s1=subset(Val,Val$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-157
s1=subset(Val,Val$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-158
s1=subset(Val,Val$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-159
s1=subset(Val,Val$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Val$Trt)
i<-160
s1=subset(Val,Val$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Val - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Bogong######################################################################################################
# 
i<-161
s1=subset(Bogong,Bogong$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-162
s1=subset(Bogong,Bogong$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-163
s1=subset(Bogong,Bogong$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-164
s1=subset(Bogong,Bogong$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-165
s1=subset(Bogong,Bogong$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-166
s1=subset(Bogong,Bogong$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.3,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-167
s1=subset(Bogong,Bogong$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-168
s1=subset(Bogong,Bogong$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-169
s1=subset(Bogong,Bogong$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Bogong$Trt)
i<-170
s1=subset(Bogong,Bogong$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Bogong - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

##Burrawan######################################################################################################
# 
i<-171
s1=subset(Burrawan,Burrawan$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-172
s1=subset(Burrawan,Burrawan$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-173
s1=subset(Burrawan,Burrawan$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-174
s1=subset(Burrawan,Burrawan$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-175
s1=subset(Burrawan,Burrawan$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}
 

#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-176
s1=subset(Burrawan,Burrawan$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-177
s1=subset(Burrawan,Burrawan$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-178
s1=subset(Burrawan,Burrawan$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-179
s1=subset(Burrawan,Burrawan$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Burrawan$Trt)
i<-180
s1=subset(Burrawan,Burrawan$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.091,ks=.03,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.00001,0.00001,0.00001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Burrawan - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Cowichan######################################################################################################
# 
i<-181
s1=subset(Cowichan,Cowichan$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-182
s1=subset(Cowichan,Cowichan$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-183
s1=subset(Cowichan,Cowichan$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-184
s1=subset(Cowichan,Cowichan$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-185
s1=subset(Cowichan,Cowichan$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-186
s1=subset(Cowichan,Cowichan$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-187
s1=subset(Cowichan,Cowichan$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-188
s1=subset(Cowichan,Cowichan$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-189
s1=subset(Cowichan,Cowichan$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Cowichan$Trt)
i<-190
s1=subset(Cowichan,Cowichan$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.00001,0.00001,0.00001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Cowichan - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")



##Fru######################################################################################################
# 
i<-191
s1=subset(Fru,Fru$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = .5), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=0.1,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-192
s1=subset(Fru,Fru$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-193
s1=subset(Fru,Fru$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-194
s1=subset(Fru,Fru$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-195
s1=subset(Fru,Fru$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.05,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-196
s1=subset(Fru,Fru$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA

#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-197
s1=subset(Fru,Fru$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-198
s1=subset(Fru,Fru$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA

#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-199
s1=subset(Fru,Fru$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA

#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Fru$Trt)
i<-200
s1=subset(Fru,Fru$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=NA
weibull[i,2]=NA
weibull[i,3]<-NA
weibull[i,4]<-NA
weibull[i,5]<-NA
summary(fit)

weibull.fit<-NA
weibull.AIC<-NA

#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.00001,0.00001,0.00001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Fru - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Kiny######################################################################################################
# 
i<-201
s1=subset(Kiny,Kiny$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=0.01,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-202
s1=subset(Kiny,Kiny$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.1,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-203
s1=subset(Kiny,Kiny$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.75), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-204
s1=subset(Kiny,Kiny$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.09,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-205
s1=subset(Kiny,Kiny$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=.3,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-206
s1=subset(Kiny,Kiny$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-207
s1=subset(Kiny,Kiny$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-208
s1=subset(Kiny,Kiny$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-209
s1=subset(Kiny,Kiny$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Kiny$Trt)
i<-210
s1=subset(Kiny,Kiny$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.00001,0.00001,0.00001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Kiny - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")


##Caroline######################################################################################################
# 
i<-211
s1=subset(Caroline,Caroline$Trt=="NPK+Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0,0))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.9,ks=0.1,A =0.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



par(mfrow=c(2,3), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - NPK+Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-212
s1=subset(Caroline,Caroline$Trt=="NP")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001,0.0001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - NP", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-213
s1=subset(Caroline,Caroline$Trt=="NPK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0000001,0.0000001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - NPK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-214
s1=subset(Caroline,Caroline$Trt=="K")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.5,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.9,ks=.03,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - K", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-215
s1=subset(Caroline,Caroline$Trt=="PK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001),upper=c(1000))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.95,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1

summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=0.09,ks=.3,A =.04)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - PK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-216
s1=subset(Caroline,Caroline$Trt=="N")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.2), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - N", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-217
s1=subset(Caroline,Caroline$Trt=="P")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=.5, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.00001,0.00001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - P", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-218
s1=subset(Caroline,Caroline$Trt=="Fence")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,0.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - Fence", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-219
s1=subset(Caroline,Caroline$Trt=="Control")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.09,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.0001,0.0001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=1,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.001,0.001,0.001),control=list(maxit=1000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - Control", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")

######################################################################################################
# 
unique(Caroline$Trt)
i<-220
s1=subset(Caroline,Caroline$Trt=="NK")
# s1=subset(CBGB,CBGB$Plot==24)
dim(s1)
#browser()
#create new CBGB frame (with appropriate column names) to put in 
# only necessary columns, so you don't get messed up
# by excluding NA's from unneeded columns (e.g., if Final_N CBGB is missing R will 
# delete the entire row whether you need Final_N for your analysis or not
t=(as.numeric(s1$Yrs_Since_Deployment))
class(t)
t1<-seq(0,7,length.out=10000)
Mt=s1$Prop_Init_C_Mass
class(Mt)
x <- data.frame(t, Mt)
#omit lines with missing CBGB (NAs)
# x<-x[order(x$t),]
# x[4,] <- NA
xNA<-na.exclude(x)
xNA

Mt<-xNA$Mt
t<-xNA$t




#Weibull function
fit<- nls((Mt) ~ exp(-(t/beta)^alpha), start =list(beta=1, alpha = 1), algorithm="port", lower=c(0.0001,0.0001))
weibull[i,1]=coef(fit)[2]
weibull[i,2]=coef(fit)[1]
weibull[i,3]<-mrt.calc(fit)
weibull[i,4]<-half.life.calc(fit)
weibull[i,5]<-sum(resid(fit)^2)
summary(fit)

weibull.fit<-exp(-(t1/weibull[i,2])^weibull[i,1])
weibull.AIC<-AIC(fit)


#Single pool 
#Method 1: Liklihood function	
singleLL = mle2(minuslogl = LLS, start = list(k = 0.5), data = list(y=Mt),method="L-BFGS-B", lower=c(0),upper=c(100))
#add 1 to K (in AIC caculation) for estimating sigma
attr(singleLL ,"df") = attr(singleLL,"df")+1
summary(singleLL)

#Extract k value
single.k[i,1]=coef(singleLL)[1]

single.exp.fit<-exp(-single.k[i,1]*t1)



#Asymptotic (method 1 only): M(t)=A+(1-A)*exp(-k*t)
#Liklihood function	
asymLL = mle2(minuslogl = LLA, start = list(k = 0.9,A=0.02), data = list(y=Mt),method="L-BFGS-B", lower=c(0.001,.001))#,control=list(maxint=10e6))
attr(asymLL ,"df") = attr(asymLL,"df")+1
summary(asymLL)

#Extract k & A value
asymptotic.k[i,1]=coef(asymLL)[1]
asymptotic.k[i,2]=coef(asymLL)[2]

asymptotic.k.fit<-asymptotic.k[i,2]+((1+asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))

#Asymptotic preds
if(i==1){predmle2.a=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])}
if(i>1){
  predmle2temp=asymptotic.k[i,2]+(1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*x[,1])
  predmle2.a=append(predmle2.a,predmle2temp)
}


#Double pool (method 1 only): Prop_Init_Massmass = A*exp(-ks*t)+(1-A)*exp(-k*t);
#Liklihood function	
start=list(k=.91,ks=.3,A =.4)
doubleLL = mle2(minuslogl = LLD, start = start, data = list(y=xNA$Mt),method="L-BFGS-B", lower=c(0.00001,0.00001,0.00001),control=list(maxit=10000, trace=TRUE, parscale=abs(unlist(start))))
attr(doubleLL ,"df") = attr(singleLL,"df")+1
summary(doubleLL)

#Extract k value; ks&A, k&(1-A)
double.k[i,1]=coef(doubleLL)[1]#ks
double.k[i,2]=coef(doubleLL)[2]#k
double.k[i,3]=coef(doubleLL)[3]#A

asymptotic.k.fit<-asymptotic.k[i,2]+((1-asymptotic.k[i,2])*exp(-asymptotic.k[i,1]*t1))
double.exp.fit<-(double.k[i,3]*exp(-double.k[i,1]*t1))+((1-double.k[i,3])*exp(-double.k[i,2]*t1))

#Double preds
if(i==1){predmle2.d=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])}
if(i>1){
  predmle2temp=double.k[i,3]*exp(-double.k[i,1]*x[,1])+(1-double.k[i,3])*exp(-double.k[i,2]*x[,1])
  predmle2.d=append(predmle2.d,predmle2temp)
}

#SummaryCBGB
Sample1xx<-AICctab(singleLL,asymLL,doubleLL, nobs=nrow(x), sort=FALSE,base=TRUE, weights=TRUE)
Sample1xx
a.aicc[i,1]=Sample1xx$dAICc[1]
a.aicc[i,2]=Sample1xx$dAICc[2]
a.aicc[i,3]=Sample1xx$dAICc[3]
a.aicc[i,4]=Sample1xx$weight[1]
a.aicc[i,5]=Sample1xx$weight[2]
a.aicc[i,6]=Sample1xx$weight[3]
a.aicc[i,7]=Sample1xx$AICc[1]
a.aicc[i,8]=Sample1xx$AICc[2]
a.aicc[i,9]=Sample1xx$AICc[3]
a.aicc[i,10]=weibull.AIC
a.aicc[i,]



# par(mfrow=c(3,4), oma=c(0,0,0,0), mar=c(4,4,1,1), mgp=c(2.4,0.8,0), cex.lab=1.25, cex.main=1.25, cex.axis=1.15)
plot(t,Mt, pch=16, col="dark grey", xlab="Yrs_Since_Deployment",ylab="Prop. C Remaining", main="Caroline - NK", xlim=c(0,8), ylim=c(0,1))
lines(t1,exp(-single.k[i,1]*t1), col="grey")
lines(t1, asymptotic.k.fit, col="mediumpurple", lty=2)
lines(t1, double.exp.fit, col="orange", lty=3)
lines(t1, weibull.fit, col="dodgerblue1", lty=1)
legend("topright", c("single", "asymp.", "double", "weibull"), col=c("grey","mediumpurple","orange","dodgerblue1"), lty=c(1,2,3,1), bty="n")




colnames(a.aicc)<-c("Single_dAICc", "Asym_dAICc", "Double_dAICc", "Single_weight", "Asym_weight", "Double_Weight", "Single_AICc", 
                    "Asym_AICc", "Double_AICc", "weibull.AIC")
head(a.aicc)
a.aicc[,3]
dim(a.aicc)

k_vals<-cbind(
  single.k,
  double.k,
  asymptotic.k,
  weibull)
head(k_vals)

colnames(k_vals)<-c("single.k", "double.ks", "double.k","double.A", "asymp.k", "asymp.A", "double.empty", "weibull.beta", "weibull.alpha", "weibull.mrt", 
                    "weibull.half.life", "weibull.RSS")
head(k_vals)
dim(k_vals)

#arrays for obs,pred,res
single.pred=array(0,dim=c(nrow(data),4))		#col: 1=Mt,2=t,3=pred,4=res
double.pred=array(0,dim=c(nrow(data),4))		#col: 1=Mt,2=t,3=pred,4=res
asymptotic.pred=array(0,dim=c(nrow(data),6))	#col: 1=Mt,2=t,3=pred,4=res
weibull.pred=array(0,dim=c(nrow(data),6))	#col: 1=Mt,2=t,3=pred,4=res

write.csv(a.aicc, "20190523_a.aicc_table.csv")
write.csv(k_vals, "20190523_k_vals_table.csv")


















